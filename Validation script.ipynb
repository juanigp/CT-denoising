{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Validation script.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIth1W4lkKkY",
        "colab_type": "text"
      },
      "source": [
        "# Tuning of hyperparameters\n",
        "#### Script to train the model multiple times using different values for batch size and learning rate. The training is done using a small subset of the total training dataset and the results are validated against a different subset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7b8223f8-1670-44b4-e3c8-235f7cd79dc7",
        "id": "G9if_8ekya5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "!git clone -l -s git://github.com/juanigp/CT-denoising.git cloned-repo\n",
        "%cd cloned-repo\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount = True)\n",
        "\n",
        "import os\n",
        "from IPython.core.debugger import set_trace\n",
        "from models.EDCNN import EDCNN\n",
        "from utils import utils\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data.sampler as sampler\n",
        "from torch.autograd import Variable\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cloned-repo'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 217, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/217)\u001b[K\rremote: Counting objects:   1% (3/217)\u001b[K\rremote: Counting objects:   2% (5/217)\u001b[K\rremote: Counting objects:   3% (7/217)\u001b[K\rremote: Counting objects:   4% (9/217)\u001b[K\rremote: Counting objects:   5% (11/217)\u001b[K\rremote: Counting objects:   6% (14/217)\u001b[K\rremote: Counting objects:   7% (16/217)\u001b[K\rremote: Counting objects:   8% (18/217)\u001b[K\rremote: Counting objects:   9% (20/217)\u001b[K\rremote: Counting objects:  10% (22/217)\u001b[K\rremote: Counting objects:  11% (24/217)\u001b[K\rremote: Counting objects:  12% (27/217)\u001b[K\rremote: Counting objects:  13% (29/217)\u001b[K\rremote: Counting objects:  14% (31/217)\u001b[K\rremote: Counting objects:  15% (33/217)\u001b[K\rremote: Counting objects:  16% (35/217)\u001b[K\rremote: Counting objects:  17% (37/217)\u001b[K\rremote: Counting objects:  18% (40/217)\u001b[K\rremote: Counting objects:  19% (42/217)\u001b[K\rremote: Counting objects:  20% (44/217)\u001b[K\rremote: Counting objects:  21% (46/217)\u001b[K\rremote: Counting objects:  22% (48/217)\u001b[K\rremote: Counting objects:  23% (50/217)\u001b[K\rremote: Counting objects:  24% (53/217)\u001b[K\rremote: Counting objects:  25% (55/217)\u001b[K\rremote: Counting objects:  26% (57/217)\u001b[K\rremote: Counting objects:  27% (59/217)\u001b[K\rremote: Counting objects:  28% (61/217)\u001b[K\rremote: Counting objects:  29% (63/217)\u001b[K\rremote: Counting objects:  30% (66/217)\u001b[K\rremote: Counting objects:  31% (68/217)\u001b[K\rremote: Counting objects:  32% (70/217)\u001b[K\rremote: Counting objects:  33% (72/217)\u001b[K\rremote: Counting objects:  34% (74/217)\u001b[K\rremote: Counting objects:  35% (76/217)\u001b[K\rremote: Counting objects:  36% (79/217)\u001b[K\rremote: Counting objects:  37% (81/217)\u001b[K\rremote: Counting objects:  38% (83/217)\u001b[K\rremote: Counting objects:  39% (85/217)\u001b[K\rremote: Counting objects:  40% (87/217)\u001b[K\rremote: Counting objects:  41% (89/217)\u001b[K\rremote: Counting objects:  42% (92/217)\u001b[K\rremote: Counting objects:  43% (94/217)\u001b[K\rremote: Counting objects:  44% (96/217)\u001b[K\rremote: Counting objects:  45% (98/217)\u001b[K\rremote: Counting objects:  46% (100/217)\u001b[K\rremote: Counting objects:  47% (102/217)\u001b[K\rremote: Counting objects:  48% (105/217)\u001b[K\rremote: Counting objects:  49% (107/217)\u001b[K\rremote: Counting objects:  50% (109/217)\u001b[K\rremote: Counting objects:  51% (111/217)\u001b[K\rremote: Counting objects:  52% (113/217)\u001b[K\rremote: Counting objects:  53% (116/217)\u001b[K\rremote: Counting objects:  54% (118/217)\u001b[K\rremote: Counting objects:  55% (120/217)\u001b[K\rremote: Counting objects:  56% (122/217)\u001b[K\rremote: Counting objects:  57% (124/217)\u001b[K\rremote: Counting objects:  58% (126/217)\u001b[K\rremote: Counting objects:  59% (129/217)\u001b[K\rremote: Counting objects:  60% (131/217)\u001b[K\rremote: Counting objects:  61% (133/217)\u001b[K\rremote: Counting objects:  62% (135/217)\u001b[K\rremote: Counting objects:  63% (137/217)\u001b[K\rremote: Counting objects:  64% (139/217)\u001b[K\rremote: Counting objects:  65% (142/217)\u001b[K\rremote: Counting objects:  66% (144/217)\u001b[K\rremote: Counting objects:  67% (146/217)\u001b[K\rremote: Counting objects:  68% (148/217)\u001b[K\rremote: Counting objects:  69% (150/217)\u001b[K\rremote: Counting objects:  70% (152/217)\u001b[K\rremote: Counting objects:  71% (155/217)\u001b[K\rremote: Counting objects:  72% (157/217)\u001b[K\rremote: Counting objects:  73% (159/217)\u001b[K\rremote: Counting objects:  74% (161/217)\u001b[K\rremote: Counting objects:  75% (163/217)\u001b[K\rremote: Counting objects:  76% (165/217)\u001b[K\rremote: Counting objects:  77% (168/217)\u001b[K\rremote: Counting objects:  78% (170/217)\u001b[K\rremote: Counting objects:  79% (172/217)\u001b[K\rremote: Counting objects:  80% (174/217)\u001b[K\rremote: Counting objects:  81% (176/217)\u001b[K\rremote: Counting objects:  82% (178/217)\u001b[K\rremote: Counting objects:  83% (181/217)\u001b[K\rremote: Counting objects:  84% (183/217)\u001b[K\rremote: Counting objects:  85% (185/217)\u001b[K\rremote: Counting objects:  86% (187/217)\u001b[K\rremote: Counting objects:  87% (189/217)\u001b[K\rremote: Counting objects:  88% (191/217)\u001b[K\rremote: Counting objects:  89% (194/217)\u001b[K\rremote: Counting objects:  90% (196/217)\u001b[K\rremote: Counting objects:  91% (198/217)\u001b[K\rremote: Counting objects:  92% (200/217)\u001b[K\rremote: Counting objects:  93% (202/217)\u001b[K\rremote: Counting objects:  94% (204/217)\u001b[K\rremote: Counting objects:  95% (207/217)\u001b[K\rremote: Counting objects:  96% (209/217)\u001b[K\rremote: Counting objects:  97% (211/217)\u001b[K\rremote: Counting objects:  98% (213/217)\u001b[K\rremote: Counting objects:  99% (215/217)\u001b[K\rremote: Counting objects: 100% (217/217)\u001b[K\rremote: Counting objects: 100% (217/217), done.\u001b[K\n",
            "remote: Compressing objects: 100% (170/170), done.\u001b[K\n",
            "remote: Total 217 (delta 107), reused 125 (delta 42), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (217/217), 39.70 MiB | 24.71 MiB/s, done.\n",
            "Resolving deltas: 100% (107/107), done.\n",
            "/content/cloned-repo\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npSXcEpVfCJf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "c4496154-6644-4ff7-95d0-60738402f01e"
      },
      "source": [
        "#csv file containing the directories of the lo res and ground truth patches\n",
        "csv_file = r'/gdrive/My Drive/patches/1.csv' \n",
        "dataset = utils.CTVolumesDataset(csv_file)\n",
        "\n",
        "#split of data in training, validation and testing data:\n",
        "#the .csv is shuffled (using the same seed everytime for repeatability)\n",
        "num_samples = len(dataset)\n",
        "total_idx = list(range(num_samples))\n",
        "random.seed(10)\n",
        "random.shuffle(total_idx)\n",
        "\n",
        "#pick 10% of samples to test\n",
        "testing_samples_percentage = 0.1\n",
        "split_index = int( num_samples * testing_samples_percentage )\n",
        "#pick the first 10% of samples in the shuffled dataset for testing\n",
        "testing_idx = total_idx[0 : split_index]\n",
        "#pick the other 90% of samples in the shuffled dataset for training\n",
        "training_idx = total_idx[split_index : num_samples]\n",
        "#pick the first 10% of samples used for training. These are the samples that are going to be used for training in this script\n",
        "training_subset_idx = training_idx[0:split_index]\n",
        "#pick the second 10% of samples used for validation\n",
        "validation_subset_idx = training_idx[split_index: 2 * split_index]\n",
        "\n",
        "training_subset_sampler = sampler.SubsetRandomSampler(training_subset_idx)\n",
        "validation_sampler = sampler.SubsetRandomSampler(validation_subset_idx)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3e2b3a07d694>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcsv_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'/gdrive/My Drive/patches/1.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCTVolumesDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#split of data in training, validation and testing data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#the .csv is shuffled (using the same seed everytime for repeatability)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cloned-repo/utils/utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, csv_file)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCTVolumesDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m#self.root_dir = root_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/gdrive/My Drive/patches/1.csv' does not exist: b'/gdrive/My Drive/patches/1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHZFm6B3n2QX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 100\n",
        "bs = 32\n",
        "lr_list = [0.01, 0.001, 0.0001, 0.00001]\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "training_subset_dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size = bs, sampler = training_subset_sampler)\n",
        "validation_dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size = bs, sampler = validation_sampler)\n",
        "\n",
        "for lr in lr_list:\n",
        "  training_loss_list = []\n",
        "  validation_loss_list = []\n",
        "  model = EDCNN()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = lr)  \n",
        "  if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "      criterion.cuda() \n",
        "  for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    num_batches = 0\n",
        "    model.train()\n",
        "    for batch, (lo_res, hi_res) in enumerate(training_subset_dataloader):\n",
        "      #add an extra dimension:\n",
        "      lo_res = utils.var_or_cuda( lo_res.unsqueeze(1) )\n",
        "      hi_res = utils.var_or_cuda(hi_res)\n",
        "      if lo_res.size()[0] != bs:\n",
        "          #print(\"batch_size != {} drop last incompatible batch\".format( bs ))\n",
        "          continue\n",
        "      num_batch += 1\n",
        "      #forward pass \n",
        "      outputs = model(lo_res)\n",
        "      loss = criterion(outputs, hi_res.unsqueeze(1))\n",
        "      epoch_loss += loss\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    print('Training epoch [{}/{}]' .format(epoch+1) )     \n",
        "    training_loss_list.append( epoch_loss/num_batches )\n",
        "      \n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    num_batches = 0\n",
        "    with torch.no_grad():\n",
        "      for batch, (lo_res, hi_res) in enumerate(validation_dataloader):\n",
        "        #add an extra dimension:\n",
        "        lo_res = utils.var_or_cuda( lo_res.unsqueeze(1) )\n",
        "        hi_res = utils.var_or_cuda(hi_res)\n",
        "        if lo_res.size()[0] != bs:\n",
        "            #print(\"batch_size != {} drop last incompatible batch\".format( bs ))\n",
        "            continue\n",
        "        num_batch += 1\n",
        "        #forward pass \n",
        "        outputs = model(lo_res)\n",
        "        loss = criterion(outputs, hi_res.unsqueeze(1))\n",
        "        epoch_loss += loss\n",
        "\n",
        "      print('Validation epoch [{}/{}]'.format(epoch+1) )     \n",
        "      validation_loss_list.append( epoch_loss/num_batches )\n",
        "    \n",
        "  training_losses.append( (training_loss_list, {\"lr\": lr, \"batch_size\" = bs} ) )\n",
        "  validation_losses.append( (validation_loss_list, {\"lr\": lr, \"batch_size\" = bs} ) )\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKAxvWMgSbkP",
        "colab_type": "code",
        "outputId": "0ea42ded-db28-40ce-fbf2-8f7ecbe313bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "len(training_loss_list)\n",
        "plt.plot(np.array(validation_loss_list)/(30*20), color = 'blue')\n",
        "plt.plot(np.array(training_loss_list)/(30*20), color = 'olive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f04ee3149e8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/1TLMrwlcSl9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6lgXcWfm54r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "bs_list = [1, 2, 4, 8, 16, 32]\n",
        "lr_list = [0.01, 0.001, 0.0001, 0.00001]\n",
        "bs_np, lr_np = np.array(bs_list), np.array(lr_list)\n",
        "bs_mat, lr_mat = np.meshgrid(bs_np, lr_np)\n",
        "bs_np = np.resize(bs_mat, -1)\n",
        "lr_np = np.resize(lr_mat, -1)\n",
        "\n",
        "num_epochs = 30\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "#for i in range(len(lr_np)):\n",
        "for i in range(1):  \n",
        "  training_loss_list = []\n",
        "  validation_loss_list = []\n",
        "\n",
        "  lr = int(lr_np[i])\n",
        "  bs = int(bs_np[i])\n",
        "  lr = 0.00005\n",
        "  bs = 32\n",
        "\n",
        "  #dataloader\n",
        "  training_subset_dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size = bs, sampler = training_subset_sampler)\n",
        "  validation_dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size = bs, sampler = validation_sampler)\n",
        "  total_step = len(training_subset_dataloader)\n",
        "\n",
        "  model = EDCNN()\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = lr)  \n",
        "  if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "      criterion.cuda()\n",
        "  for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    for batch, (lo_res, hi_res) in enumerate(training_subset_dataloader):\n",
        "      #add an extra dimension:\n",
        "      lo_res = utils.var_or_cuda( lo_res.unsqueeze(1) )\n",
        "      hi_res = utils.var_or_cuda(hi_res)\n",
        "      if lo_res.size()[0] != bs:\n",
        "          print(\"batch_size != {} drop last incompatible batch\".format( bs ))\n",
        "          continue\n",
        "\n",
        "      #forward pass \n",
        "      outputs = model(lo_res)\n",
        "      loss = criterion(outputs, hi_res.unsqueeze(1))\n",
        "      epoch_loss += loss\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if (batch+1) % 1 == 0:\n",
        "          print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "              .format(epoch+1, num_epochs, batch+1, total_step, loss.item()))    \n",
        "    training_loss_list.append(epoch_loss)\n",
        "    \n",
        "  \n",
        "    model.eval()\n",
        "    model.zero_grad()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      for batch, (lo_res, hi_res) in enumerate(validation_dataloader):\n",
        "\n",
        "        #add an extra dimension:\n",
        "        lo_res = utils.var_or_cuda( lo_res.unsqueeze(1) )\n",
        "        hi_res = utils.var_or_cuda(hi_res)\n",
        "        if lo_res.size()[0] != bs:\n",
        "            print(\"batch_size != {} drop last incompatible batch\".format( bs ))\n",
        "            continue\n",
        "\n",
        "        #forward pass \n",
        "        outputs = model(lo_res)\n",
        "        loss = criterion(outputs, hi_res.unsqueeze(1))\n",
        "        epoch_loss += loss\n",
        "\n",
        "        if (batch+1) % 1 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                .format(epoch+1, num_epochs, batch+1, total_step, loss.item()))\n",
        "      validation_loss_list.append(epoch_loss)\n",
        "    \n",
        "  training_losses.append(training_loss_list)\n",
        "  validation_losses.append(validation_loss_list)\n",
        "  '''\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}