{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "REDCNN.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itvuHsMtyEeO",
        "colab_type": "text"
      },
      "source": [
        "# Training of EDCNN\n",
        "### Comments:\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suh3h4QoyEeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "using_colab = True\n",
        "\n",
        "if using_colab :\n",
        "  !git clone -l -s git://github.com/juanigp/CT-denoising.git cloned-repo\n",
        "  %cd cloned-repo\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive', force_remount = True)\n",
        "\n",
        "\n",
        "import os\n",
        "from IPython.core.debugger import set_trace\n",
        "from models.EDCNN import EDCNN\n",
        "from utils import utils\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data.sampler as sampler\n",
        "from torch.autograd import Variable\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ4mkmrCNN-X",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters, model, dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "504cgdHlyEez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hyperparameters:\n",
        "num_epochs = 1000\n",
        "batch_size = 16\n",
        "learning_rate = 0.0001\n",
        "\n",
        "#instantiating the model:\n",
        "model = EDCNN()\n",
        "#model.double()\n",
        "\n",
        "#loss function\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "#optimizer algorithm\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "#if gpu available\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "    criterion.cuda()\n",
        "    \n",
        "#dataset\n",
        "if using_colab:\n",
        "  csv_file = r'/gdrive/My Drive/patches/1.csv'  \n",
        "else:\n",
        "  #should be XCT instead of 500FBP!!\n",
        "  csv_file = r'C:/Users/Juan Pisula/Desktop/ct_images/patches/100_FBPPhil_500FBP.csv'\n",
        "\n",
        "#dataset, dataloader  \n",
        "dataset = utils.CTVolumesDataset(csv_file)\n",
        "dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRHBRCjZOSpP",
        "colab_type": "text"
      },
      "source": [
        "## Inspecting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRynJNjAyEfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "#inspect training examples\n",
        "\n",
        "batches = list(dataloader)\n",
        "\n",
        "print(len(batches)) #how many batches\n",
        "batch = batches[20]\n",
        "print( len( batch ) ) #length of the batches (2 = lo res, hi res)\n",
        "print( batch[0].size() ) #size of the lo res volumes of the batch: batch_size volumes, size of volume\n",
        "plt.imshow(batch[1][0][10][:][:], cmap = 'gray' )\n",
        "\n",
        "#enu = enumerate(dataloader)\n",
        "#len(dataloader) # = amount of patches / batch size\n",
        "\n",
        "(lo_res, hi_res) = batch\n",
        "print(lo_res.size())\n",
        "lo_res = lo_res.unsqueeze(1)\n",
        "print(lo_res.size())\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdL61bkjOdoM",
        "colab_type": "text"
      },
      "source": [
        "## Training the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGdq4B34I0xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKd4KwYOyEfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#directory to save the model\n",
        "if using_colab:\n",
        "  models_dir = r'/gdrive/My Drive/models' \n",
        "else:\n",
        "  models_dir = r'C:/Users/Juan Pisula/Desktop/ct_images'  \n",
        "\n",
        "#file to record metrics  \n",
        "metrics_file_name = 'training_loss.csv' \n",
        "metrics_file_dir = os.path.join(models_dir, metrics_file_name)\n",
        "\n",
        "#loading a previously trained model\n",
        "resume_checkpoint = False\n",
        "checkpoint_file_dir = os.path.join(models_dir,'REDCNN_checkpoint_epoch_0.pth.tar')\n",
        "if resume_checkpoint:\n",
        "  checkpoint = torch.load(checkpoint_file_dir)\n",
        "  start_epoch = checkpoint['epoch']\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "else:\n",
        "  start_epoch = 0\n",
        "\n",
        "\n",
        "#training\n",
        "total_step = len(dataloader)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "  \n",
        "    for i, (lo_res, hi_res) in enumerate(dataloader):\n",
        "        #add an extra dimension:\n",
        "        lo_res = utils.var_or_cuda( lo_res.unsqueeze(1) )\n",
        "        hi_res = utils.var_or_cuda(hi_res)\n",
        "        if lo_res.size()[0] != batch_size:\n",
        "            print(\"batch_size != {} drop last incompatible batch\".format( batch_size ))\n",
        "            continue\n",
        "            \n",
        "        #forward pass \n",
        "        outputs = model(lo_res)\n",
        "        loss = criterion(outputs, hi_res.unsqueeze(1))\n",
        "        #backward & optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        if (i+1) % 1 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "            \n",
        "    #save model after epoch   \n",
        "    checkpoint_file_dir = os.path.join(models_dir, 'REDCNN_checkpoint_epoch_' + str(epoch + 1) + '.pth.tar' )\n",
        "    \n",
        "    save_checkpoint({\n",
        "        'epoch': epoch + 1,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer' : optimizer.state_dict(),\n",
        "    }, checkpoint_file_dir)\n",
        "\n",
        "    csv_line = str(loss.item()) + ',' + str(epoch) + '\\n'\n",
        "    with open(metrics_file_dir , 'a+') as file:\n",
        "        file.write(csv_line)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}